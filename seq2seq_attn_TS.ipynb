{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda= torch.cuda.is_available\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "\n",
    "predict integer-valued time series data for prediction with seq2seq method, using artificial embedding associated with one-hot representation of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Doudou/anaconda/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "path = '/Users/Doudou/Documents/ScolaritÃ©/MASH/Kaggle/Recruiting holding'\n",
    "\n",
    "from pylab import rcParams\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "def RMLSE(p,a):\n",
    "    x = np.sqrt(np.mean((np.log(p+1)-np.log(a+1))**2))\n",
    "    return x\n",
    "\n",
    "df_air_reserve = pd.read_csv(path+'/air_reserve.csv', parse_dates=['visit_datetime','reserve_datetime'], encoding='utf-8')\n",
    "df_air_store_info = pd.read_csv(path+'/air_store_info.csv', encoding='utf-8')\n",
    "df_air_visit_data = pd.read_csv(path+'/air_visit_data.csv', parse_dates=['visit_date'], encoding='utf-8')\n",
    "df_date_info = pd.read_csv(path+'/date_info.csv', parse_dates=['calendar_date'], encoding='utf-8')\n",
    "df_hpg_reserve = pd.read_csv(path+'/hpg_reserve.csv', parse_dates=['visit_datetime','reserve_datetime'], encoding='utf-8')\n",
    "df_hpg_store_info = pd.read_csv(path+'/hpg_store_info.csv', encoding='utf-8')\n",
    "df_sample_submission = pd.read_csv(path+'/sample_submission.csv', encoding='utf-8')\n",
    "df_store_id_relation = pd.read_csv(path+'/store_id_relation.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission['air_store_id'] = df_sample_submission.id.apply(lambda d: str(d)[:-11])\n",
    "df_sample_submission['visit_date'] = df_sample_submission.id.apply(lambda d: str(d)[-10:])\n",
    "df_sample_submission.visit_date = pd.to_datetime(df_sample_submission.visit_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_visit_data = pd.concat((df_air_visit_data, df_sample_submission.drop('id', axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_visit_data_save = df_air_visit_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only get recent dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Doudou/anaconda/lib/python3.5/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "df_air_visit_data = df_air_visit_data.loc[(df_air_visit_data.visit_date>datetime.strptime('2017-01-01', '%Y-%m-%d').date())*(df_air_visit_data.visit_date<=datetime.strptime('2017-04-22', '%Y-%m-%d').date())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding the missing/closing dates with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "asis = np.unique(df_air_visit_data.air_store_id.values)\n",
    "idx = pd.date_range(df_air_visit_data.loc[df_air_visit_data.air_store_id==asis[0]].visit_date.min(), \n",
    "                    df_air_visit_data.loc[df_air_visit_data.air_store_id==asis[0]].visit_date.max())\n",
    "\n",
    "df_reindexed = df_air_visit_data.loc[df_air_visit_data.air_store_id==asis[0]].set_index(['visit_date']).reindex(idx, fill_value=0)\n",
    "df_reindexed.air_store_id = asis[0]\n",
    "\n",
    "for asi in asis[1:]:\n",
    "    idx = pd.date_range(df_air_visit_data.loc[df_air_visit_data.air_store_id==asi].visit_date.min(), \n",
    "                    df_air_visit_data.loc[df_air_visit_data.air_store_id==asi].visit_date.max())\n",
    "    df_temp = df_air_visit_data.loc[df_air_visit_data.air_store_id==asi].set_index(['visit_date']).reindex(idx, fill_value=0)\n",
    "    df_temp.air_store_id = asi\n",
    "    df_reindexed = pd.concat((df_reindexed, df_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88795, 3)\n"
     ]
    }
   ],
   "source": [
    "df_reindexed['visit_date'] = df_reindexed.index\n",
    "df_reindexed.reset_index(drop=True, inplace = True)\n",
    "print(df_reindexed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_visit_data = df_reindexed.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_reindexed=df_air_visit_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>36</td>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>37</td>\n",
       "      <td>2017-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>44</td>\n",
       "      <td>2017-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>37</td>\n",
       "      <td>2017-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>46</td>\n",
       "      <td>2017-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>36</td>\n",
       "      <td>2017-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>39</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>16</td>\n",
       "      <td>2017-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88765</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88766</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88767</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88768</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88769</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88770</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88771</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88772</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88773</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88774</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88775</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88776</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88777</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88778</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88779</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88780</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88781</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88782</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88783</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88784</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88785</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88786</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88787</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88788</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88789</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88790</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88791</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88792</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88793</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88794</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-04-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88795 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               air_store_id  visitors visit_date\n",
       "0      air_00a91d42b08b08d9        17 2017-01-04\n",
       "1      air_00a91d42b08b08d9        22 2017-01-05\n",
       "2      air_00a91d42b08b08d9        36 2017-01-06\n",
       "3      air_00a91d42b08b08d9        21 2017-01-07\n",
       "4      air_00a91d42b08b08d9         0 2017-01-08\n",
       "5      air_00a91d42b08b08d9         0 2017-01-09\n",
       "6      air_00a91d42b08b08d9        37 2017-01-10\n",
       "7      air_00a91d42b08b08d9        27 2017-01-11\n",
       "8      air_00a91d42b08b08d9        15 2017-01-12\n",
       "9      air_00a91d42b08b08d9        44 2017-01-13\n",
       "10     air_00a91d42b08b08d9        17 2017-01-14\n",
       "11     air_00a91d42b08b08d9         0 2017-01-15\n",
       "12     air_00a91d42b08b08d9        20 2017-01-16\n",
       "13     air_00a91d42b08b08d9        24 2017-01-17\n",
       "14     air_00a91d42b08b08d9        37 2017-01-18\n",
       "15     air_00a91d42b08b08d9        22 2017-01-19\n",
       "16     air_00a91d42b08b08d9        46 2017-01-20\n",
       "17     air_00a91d42b08b08d9        11 2017-01-21\n",
       "18     air_00a91d42b08b08d9         0 2017-01-22\n",
       "19     air_00a91d42b08b08d9        18 2017-01-23\n",
       "20     air_00a91d42b08b08d9        29 2017-01-24\n",
       "21     air_00a91d42b08b08d9        26 2017-01-25\n",
       "22     air_00a91d42b08b08d9        36 2017-01-26\n",
       "23     air_00a91d42b08b08d9        39 2017-01-27\n",
       "24     air_00a91d42b08b08d9         7 2017-01-28\n",
       "25     air_00a91d42b08b08d9         0 2017-01-29\n",
       "26     air_00a91d42b08b08d9        16 2017-01-30\n",
       "27     air_00a91d42b08b08d9        28 2017-01-31\n",
       "28     air_00a91d42b08b08d9        27 2017-02-01\n",
       "29     air_00a91d42b08b08d9        24 2017-02-02\n",
       "...                     ...       ...        ...\n",
       "88765  air_fff68b929994bfbd         8 2017-03-24\n",
       "88766  air_fff68b929994bfbd         7 2017-03-25\n",
       "88767  air_fff68b929994bfbd         3 2017-03-26\n",
       "88768  air_fff68b929994bfbd         4 2017-03-27\n",
       "88769  air_fff68b929994bfbd         9 2017-03-28\n",
       "88770  air_fff68b929994bfbd         2 2017-03-29\n",
       "88771  air_fff68b929994bfbd         5 2017-03-30\n",
       "88772  air_fff68b929994bfbd         5 2017-03-31\n",
       "88773  air_fff68b929994bfbd         9 2017-04-01\n",
       "88774  air_fff68b929994bfbd         2 2017-04-02\n",
       "88775  air_fff68b929994bfbd         2 2017-04-03\n",
       "88776  air_fff68b929994bfbd         4 2017-04-04\n",
       "88777  air_fff68b929994bfbd         6 2017-04-05\n",
       "88778  air_fff68b929994bfbd         6 2017-04-06\n",
       "88779  air_fff68b929994bfbd         9 2017-04-07\n",
       "88780  air_fff68b929994bfbd         4 2017-04-08\n",
       "88781  air_fff68b929994bfbd         5 2017-04-09\n",
       "88782  air_fff68b929994bfbd         6 2017-04-10\n",
       "88783  air_fff68b929994bfbd         1 2017-04-11\n",
       "88784  air_fff68b929994bfbd         6 2017-04-12\n",
       "88785  air_fff68b929994bfbd         1 2017-04-13\n",
       "88786  air_fff68b929994bfbd         5 2017-04-14\n",
       "88787  air_fff68b929994bfbd         7 2017-04-15\n",
       "88788  air_fff68b929994bfbd         7 2017-04-16\n",
       "88789  air_fff68b929994bfbd         3 2017-04-17\n",
       "88790  air_fff68b929994bfbd         6 2017-04-18\n",
       "88791  air_fff68b929994bfbd         2 2017-04-19\n",
       "88792  air_fff68b929994bfbd         2 2017-04-20\n",
       "88793  air_fff68b929994bfbd         4 2017-04-21\n",
       "88794  air_fff68b929994bfbd         5 2017-04-22\n",
       "\n",
       "[88795 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_reindexed.visitors = (df_reindexed.visitors-df_reindexed.visitors%5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reindexed['visitors']=df_reindexed['visitors'].astype(int, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "win_X = 21\n",
    "win_y = 7\n",
    "\n",
    "SOS_token = int(df_reindexed.visitors.max()+1)\n",
    "EOS_token = int(df_reindexed.visitors.max()+2)\n",
    "\n",
    "ds = np.unique(df_reindexed.air_store_id.values)[:1]\n",
    "\n",
    "pairs_TS = []\n",
    "\n",
    "for asi in ds:\n",
    "    df_temp = df_reindexed.set_index(['air_store_id', 'visit_date']).loc[asi]\n",
    "    \n",
    "    pairs_one_TS = [(Variable(torch.LongTensor(np.expand_dims(np.insert(df_temp.iloc[i:i+win_X].values,win_X, EOS_token),\n",
    "                                                              axis=1)).view(-1,1)), \n",
    "                     Variable(torch.LongTensor(np.expand_dims(np.insert(df_temp.iloc[i+win_X:i+win_X+win_y].values,win_y, EOS_token),\n",
    "                                                              axis=1)).view(-1,1))) \n",
    "                    for i in np.arange(df_temp.shape[0]-win_X-win_y)]\n",
    "    \n",
    "    pairs_TS = pairs_TS + pairs_one_TS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "    17\n",
       "     0\n",
       "    20\n",
       "    24\n",
       "    37\n",
       "    22\n",
       "    46\n",
       "   879\n",
       " [torch.LongTensor of size 8x1], Variable containing:\n",
       "    11\n",
       "     0\n",
       "    18\n",
       "    29\n",
       "    26\n",
       "    36\n",
       "    39\n",
       "   879\n",
       " [torch.LongTensor of size 8x1])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_TS[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with traditionnal decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-decoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module): #nn.Module = base class for all NN modules --> each model subclass this class\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding=nn.Embedding(input_size, hidden_size) # lookup table that stores embedding of fixed dictionary\n",
    "        # input_size is the number of variable to embed\n",
    "        # hidden_size is the number of dimensions for each embedding\n",
    "        self.gru=nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1) # view(shape) returns self tensors data with a different shape\n",
    "        output = embedded\n",
    "        for i in np.arange(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "            \n",
    "    def initHidden(self):\n",
    "        result=Variable(torch.zeros(1,1,self.hidden_size)) # creates a tensor of zeros, compatible with automatic gradient computing\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding=nn.Embedding(output_size, hidden_size)\n",
    "        self.gru=nn.GRU(hidden_size, hidden_size)\n",
    "        self.out=nn.Linear(hidden_size, output_size)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output=self.embedding(input).view(1,1,-1)\n",
    "        for i in np.arange(self.n_layers):\n",
    "            output=F.relu(output)\n",
    "            output, hidden=self.gru(output, hidden)\n",
    "        output=self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        result=Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "learning_rate=0.01\n",
    "teacher_forcing_ratio=0.2\n",
    "\n",
    "training_pairs=[random.choice(pairs_TS[:-10]) for i in np.arange(n_iters)]\n",
    "\n",
    "hidden_size = 256\n",
    "MAX_LENGTH = training_pairs[0][0].shape[0]\n",
    "\n",
    "encoder1=EncoderRNN(EOS_token+1, hidden_size)\n",
    "decoder1=DecoderRNN(hidden_size, EOS_token+1)\n",
    "use_cuda=False\n",
    "\n",
    "encoder_optimizer=optim.SGD(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer=optim.SGD(decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "\n",
    "for i in np.arange(n_iters):\n",
    "\n",
    "    encoder_hidden = encoder1.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = training_pairs[i][0]\n",
    "    target_variable = training_pairs[i][1]\n",
    "    \n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder1.hidden_size))\n",
    "\n",
    "    loss=0\n",
    "\n",
    "    for ei in np.arange(input_length):\n",
    "        encoder_output, encoder_hidden = encoder1(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "\n",
    "    #decoder_input=Variable(torch.LongTensor([[int(input_variable[ei-1].data[0])]]))\n",
    "    decoder_input=Variable(torch.LongTensor([[SOS_token]]))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for di in np.arange(target_length):\n",
    "            decoder_output, decoder_hidden=decoder1(decoder_input, decoder_hidden)\n",
    "            loss+=criterion(decoder_output, target_variable[di])\n",
    "            decoder_input=target_variable[di]\n",
    "\n",
    "    else:\n",
    "        for di in np.arange(target_length):\n",
    "            decoder_output, decoder_hidden=decoder1(decoder_input, decoder_hidden)\n",
    "\n",
    "            # we want to extract the best prediction (highest softmax-estimated probability value, see DecoderRNN.forward function)\n",
    "            # we then select the index related to the highest NLLL\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "\n",
    "            #decoder_input=Variable(torch.LongTensor([[SOS_token]]))\n",
    "            decoder_input=Variable(torch.LongTensor([[top_index[0][0]]]))\n",
    "\n",
    "            loss+=criterion(decoder_output, target_variable[di])\n",
    "\n",
    "            if top_index[0][0]==EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    total_loss.append(loss.data[0]/target_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c22fd6630>]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c19961f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 10\n",
    "testing_pairs=[random.choice(pairs_TS[-10:]) for i in range(n_tests)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#input_variable = variableFromSentence(input_lang, 'je suis institutrice .')\n",
    "decoder_sentences = []\n",
    "\n",
    "for tp in testing_pairs:\n",
    "    input_variable = tp[0]\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden=encoder1.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder1.hidden_size))\n",
    "\n",
    "    for ei in np.arange(input_length):\n",
    "        encoder_output, encoder_hidden = encoder1(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]+encoder_outputs[ei]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[int(SOS_token)]]))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words=[]\n",
    "\n",
    "    for di in np.arange(win_y):\n",
    "        decoder_output, decoder_hidden=decoder1(decoder_input, decoder_hidden)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "\n",
    "        decoded_words.append(top_index[0][0])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[top_index[0][0]]]))\n",
    "    \n",
    "    decoder_sentences.append(decoded_words+[EOS_token])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38, 39, 37, 4, 0, 0, 28, 879],\n",
       " [18, 0, 15, 36, 33, 40, 28, 879],\n",
       " [18, 31, 28, 42, 39, 37, 4, 879],\n",
       " [35, 29, 17, 9, 0, 17, 43, 879],\n",
       " [38, 39, 37, 4, 0, 0, 28, 879],\n",
       " [30, 52, 33, 38, 7, 0, 33, 879],\n",
       " [0, 18, 29, 26, 36, 39, 7, 879],\n",
       " [18, 0, 15, 36, 33, 40, 28, 879],\n",
       " [35, 29, 17, 9, 0, 17, 43, 879],\n",
       " [7, 0, 43, 30, 52, 33, 38, 879]]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34  39   0   0  19  35  17 879]\n",
      "[ 17   9   0  17  43  28  34 879]\n",
      "[ 17  43  28  34  39   0   0 879]\n",
      "[ 29  17   9   0  17  43  28 879]\n",
      "[ 34  39   0   0  19  35  17 879]\n",
      "[ 28  34  39   0   0  19  35 879]\n",
      "[  9   0  17  43  28  34  39 879]\n",
      "[ 17   9   0  17  43  28  34 879]\n",
      "[ 29  17   9   0  17  43  28 879]\n",
      "[ 39   0   0  19  35  17  38 879]\n"
     ]
    }
   ],
   "source": [
    "for i,tp in enumerate(testing_pairs):\n",
    "    print(np.array(tp[1].data.view(1,-1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17593399633\n",
      "1.31020051339\n",
      "1.41284440823\n",
      "1.38150891148\n",
      "2.17593399633\n",
      "1.83461435122\n",
      "1.46366504887\n",
      "1.31020051339\n",
      "1.38150891148\n",
      "1.48561956813\n"
     ]
    }
   ],
   "source": [
    "total_loss=[]\n",
    "\n",
    "for i,tp in enumerate(testing_pairs):\n",
    "    e=RMLSE((np.array(tp[1].data.view(1,-1)).flatten()),\n",
    "                np.array(decoder_sentences[i]))\n",
    "    print(e)\n",
    "    total_loss.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5932030218826134"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with attention decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module): #nn.Module = base class for all NN modules --> each model subclass this class\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding=nn.Embedding(input_size, hidden_size)\n",
    "        self.gru=nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1) # view(shape) returns self tensors data with a different shape\n",
    "        output = embedded\n",
    "        for i in np.arange(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        result=Variable(torch.zeros(1,1,self.hidden_size)) # creates a tensor of zeros, compatible with automatic gradient computing\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder_RNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, \n",
    "                 max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.dropout_p=dropout_p\n",
    "        self.max_length=max_length\n",
    "        \n",
    "        self.embedding=nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        # attention layer gets decoder's prev_hidden layer (initialized with encoder's hidden layer) and decoder's input\n",
    "        # the attention mechanism is simply a linear filtering method, outputing a focused transformation of the input\n",
    "        \n",
    "        self.attn=nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine=nn.Linear(self.hidden_size*2,self.hidden_size)\n",
    "        self.dropout=nn.Dropout(self.dropout_p)\n",
    "        self.gru=nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out=nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded=self.embedding(input).view(1,1,-1)\n",
    "        embedded=self.dropout(embedded)\n",
    "        \n",
    "        attn_weights=torch.cat((embedded[0], hidden[0]), dim=1)\n",
    "        attn_weights=F.softmax(self.attn(attn_weights), dim=1)\n",
    "        \n",
    "        # bmm is a batch matrix multiplication for 3D tensors with first dimension equals number of matrices\n",
    "        # unsqueeze(d) insert a dimension of size 1 at position d\n",
    "        \n",
    "        attn_applied=torch.bmm(attn_weights.unsqueeze(0), \n",
    "                               encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output=torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output=self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        for i in np.arange(self.n_layers):\n",
    "            output=F.relu(output)\n",
    "            output, hidden=self.gru(output, hidden)\n",
    "            \n",
    "        output=F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result=Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "learning_rate=0.01\n",
    "teacher_forcing_ratio=0.2\n",
    "\n",
    "training_pairs=[random.choice(pairs_TS[:-10]) for i in np.arange(n_iters)]\n",
    "\n",
    "hidden_size = 256\n",
    "\n",
    "MAX_LENGTH = training_pairs[0][0].shape[0]\n",
    "max_length = MAX_LENGTH\n",
    "\n",
    "encoder=EncoderRNN(EOS_token+1, hidden_size)\n",
    "decoder_attn=AttentionDecoder_RNN(hidden_size, EOS_token+1)\n",
    "use_cuda=False\n",
    "\n",
    "encoder_optimizer=optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer=optim.SGD(decoder_attn.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion=nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 6min 42s, sys: 13min 13s, total: 1h 19min 56s\n",
      "Wall time: 32min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "for i in np.arange(n_iters):\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = training_pairs[i][0]\n",
    "    target_variable = training_pairs[i][1]\n",
    "    \n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "\n",
    "    loss=0\n",
    "\n",
    "    for ei in np.arange(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "    \n",
    "    #decoder_input=Variable(torch.LongTensor([[int(input_variable[ei-1].data[0])]]))\n",
    "\n",
    "    decoder_input=Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        for di in np.arange(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention=decoder_attn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss+=criterion(decoder_output, target_variable[di])\n",
    "            decoder_input=target_variable[di]\n",
    "\n",
    "    else:\n",
    "        \n",
    "        for di in np.arange(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention=decoder_attn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            \n",
    "            decoder_input=Variable(torch.LongTensor([[top_index[0][0]]]))\n",
    "            #decoder_input=Variable(torch.LongTensor([[SOS_token]]))\n",
    "            \n",
    "            loss+=criterion(decoder_output, target_variable[di])\n",
    "\n",
    "            if top_index[0][0]==EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    total_loss.append(loss.data[0]/target_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c22fba940>]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxPx/CxoRhG1aQyAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c19333390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_variable = variableFromSentence(input_lang, 'je suis institutrice .')\n",
    "decoder_sentences = []\n",
    "\n",
    "for tp in training_pairs[:20]:\n",
    "    input_variable = tp[0]\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden=encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "\n",
    "    for ei in np.arange(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]+encoder_outputs[ei]\n",
    "\n",
    "    #decoder_input = Variable(torch.LongTensor([[int(input_variable.data[-2])]]))\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words=[]\n",
    "\n",
    "    for di in np.arange(win_y):\n",
    "        decoder_output, decoder_hidden, decoder_attention=decoder_attn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "\n",
    "        #if top_index[0][0]==EOS_token:\n",
    "        #    decoded_words.append('<EOS_token>')\n",
    "        #    break\n",
    "        #else:\n",
    "            #decoded_words.append(output_lang.index2word[top_index[0][0]])\n",
    "        decoded_words.append(top_index[0][0])\n",
    "\n",
    "        # we use guess as new input for the decoder\n",
    "        #decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "        decoder_input = Variable(torch.LongTensor([[top_index[0][0]]]))\n",
    "        \n",
    "    decoded_words.append(EOS_token)\n",
    "    decoder_sentences.append(decoded_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  16,  28,  27,  24,  37,  23, 879],\n",
       "       [ 52,  33,  38,   7,   0,  33,  17, 879],\n",
       "       [ 33,  17,  35,  29,  17,   9,   0, 879],\n",
       "       [  9,   0,  39,  28,  42,  39,  37, 879],\n",
       "       [  0,  24,  41,  52,  35,  45,  18, 879],\n",
       "       [ 29,  18,   0,  18,  31,  28,  38, 879],\n",
       "       [ 33,  29,  18,   0,  18,  31,  28, 879],\n",
       "       [  7,   0,  33,  17,  35,  29,  17, 879],\n",
       "       [ 23,  27,  34,   7,   0,  43,  30, 879],\n",
       "       [ 28,  42,  39,  37,   4,   0,   0, 879],\n",
       "       [ 23,   0,  37,  32,  15,  30,  26, 879],\n",
       "       [ 40,  28,  11,   0,  34,  19,  17, 879],\n",
       "       [  0,   0,  24,  41,  52,  35,  45, 879],\n",
       "       [ 19,  17,  33,  29,  18,   0,  18, 879],\n",
       "       [ 38,   7,   0,  33,  17,  35,  29, 879],\n",
       "       [  0,  37,  32,  15,  30,  26,   0, 879],\n",
       "       [ 52,  35,  45,  18,   0,  15,  36, 879],\n",
       "       [ 52,  35,  45,  18,   0,  15,  36, 879],\n",
       "       [  0,  33,  17,  35,  29,  17,   9, 879],\n",
       "       [ 17,  35,  29,  17,   9,   0,  17, 879]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(decoder_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  16  28  27  24  37  23 879]\n",
      "[ 52  33  38   7   0  33  17 879]\n",
      "[ 33  17  35  29  17   9   0 879]\n",
      "[  9   0  39  28  42  39  37 879]\n",
      "[  0  24  41  52  35  45  18 879]\n",
      "[ 29  18   0  18  31  28  38 879]\n",
      "[ 33  29  18   0  18  31  28 879]\n",
      "[  7   0  33  17  35  29  17 879]\n",
      "[ 23  27  34   7   0  43  30 879]\n",
      "[ 28  42  39  37   4   0   0 879]\n",
      "[ 23   0  37  32  15  30  26 879]\n",
      "[ 40  28  11   0  34  19  17 879]\n",
      "[  0   0  24  41  52  35  45 879]\n",
      "[ 19  17  33  29  18   0  18 879]\n",
      "[ 38   7   0  33  17  35  29 879]\n",
      "[  0  37  32  15  30  26   0 879]\n",
      "[ 52  35  45  18   0  15  36 879]\n",
      "[ 52  35  45  18   0  15  36 879]\n",
      "[  0  33  17  35  29  17   9 879]\n",
      "[ 17  35  29  17   9   0  17 879]\n"
     ]
    }
   ],
   "source": [
    "for i,tp in enumerate(training_pairs[:20]):\n",
    "    print(np.array(tp[1].data.view(1,-1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "total_RMLSE=[]\n",
    "\n",
    "for i,tp in enumerate(training_pairs[:20]):\n",
    "    total_RMLSE.append(RMLSE((np.array(tp[1].data.view(1,-1)).flatten())[:-2],\n",
    "                np.array(decoder_sentences[i])[:-2]))\n",
    "    print(total_RMLSE[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 10\n",
    "\n",
    "testing_pairs=[pairs_TS[-10:][i] for i in np.arange(n_tests)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#input_variable = variableFromSentence(input_lang, 'je suis institutrice .')\n",
    "decoder_sentences = []\n",
    "\n",
    "for tp in testing_pairs:\n",
    "    input_variable = tp[0]\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden=encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "\n",
    "    for ei in np.arange(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]+encoder_outputs[ei]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words=[]\n",
    "\n",
    "    for di in np.arange(win_y):\n",
    "        decoder_output, decoder_hidden, decoder_attention=decoder_attn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "\n",
    "        #if top_index[0][0]==EOS_token:\n",
    "        #    decoded_words.append('<EOS_token>')\n",
    "        #    break\n",
    "        #else:\n",
    "            #decoded_words.append(output_lang.index2word[top_index[0][0]])\n",
    "        decoded_words.append(top_index[0][0])\n",
    "\n",
    "        # we use guess as new input for the decoder\n",
    "        #decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "        decoder_input = Variable(torch.LongTensor([[top_index[0][0]]]))\n",
    "        \n",
    "    decoded_words.append(EOS_token)\n",
    "    decoder_sentences.append(decoded_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(decoder_sentences)*np.array(np.array([np.array(tp[1].data.view(1,-1)).flatten() \n",
    "          for i, tp in enumerate(testing_pairs)])!=0,dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39  37   4   0   0  28  23  27  34   7   0  43  30  52  33  38   7   0\n",
      "  33  17  35 879]\n",
      "[ 37   4   0   0  28  23  27  34   7   0  43  30  52  33  38   7   0  33\n",
      "  17  35  29 879]\n",
      "[  4   0   0  28  23  27  34   7   0  43  30  52  33  38   7   0  33  17\n",
      "  35  29  17 879]\n",
      "[  0   0  28  23  27  34   7   0  43  30  52  33  38   7   0  33  17  35\n",
      "  29  17   9 879]\n",
      "[  0  28  23  27  34   7   0  43  30  52  33  38   7   0  33  17  35  29\n",
      "  17   9   0 879]\n",
      "[ 28  23  27  34   7   0  43  30  52  33  38   7   0  33  17  35  29  17\n",
      "   9   0  17 879]\n",
      "[ 23  27  34   7   0  43  30  52  33  38   7   0  33  17  35  29  17   9\n",
      "   0  17  43 879]\n",
      "[ 27  34   7   0  43  30  52  33  38   7   0  33  17  35  29  17   9   0\n",
      "  17  43  28 879]\n",
      "[ 34   7   0  43  30  52  33  38   7   0  33  17  35  29  17   9   0  17\n",
      "  43  28  34 879]\n",
      "[  7   0  43  30  52  33  38   7   0  33  17  35  29  17   9   0  17  43\n",
      "  28  34  39 879]\n"
     ]
    }
   ],
   "source": [
    "for i,tp in enumerate(testing_pairs):\n",
    "    print(np.array(tp[0].data.view(1,-1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9ea2e7514019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.array(decoder_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29  17   9   0  17  43  28 879]\n",
      "[ 17   9   0  17  43  28  34 879]\n",
      "[  9   0  17  43  28  34  39 879]\n",
      "[  0  17  43  28  34  39   0 879]\n",
      "[ 17  43  28  34  39   0   0 879]\n",
      "[ 43  28  34  39   0   0  19 879]\n",
      "[ 28  34  39   0   0  19  35 879]\n",
      "[ 34  39   0   0  19  35  17 879]\n",
      "[ 39   0   0  19  35  17  38 879]\n",
      "[  0   0  19  35  17  38  55 879]\n"
     ]
    }
   ],
   "source": [
    "for i,tp in enumerate(testing_pairs):\n",
    "    print(np.array(tp[1].data.view(1,-1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31721049126\n",
      "1.35023103054\n",
      "0.256910158026\n",
      "2.40008820918\n",
      "0.822947775808\n",
      "2.22432912778\n",
      "0.856308597558\n",
      "0.908237012409\n",
      "1.9594046264\n",
      "1.24488246749\n"
     ]
    }
   ],
   "source": [
    "total_RMLSE=[]\n",
    "\n",
    "for i,tp in enumerate(testing_pairs):\n",
    "    total_RMLSE.append(RMLSE((np.array(tp[1].data.view(1,-1)).flatten()),\n",
    "                np.array(decoder_sentences[i])))\n",
    "    print(total_RMLSE[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00608087576\n",
      "0.991416423752\n",
      "0.296654297787\n",
      "0.13907205757\n",
      "0.13907205757\n",
      "1.53017791442\n",
      "0.293673506607\n",
      "0.299698633757\n",
      "1.25216659308\n",
      "0.284641487567\n"
     ]
    }
   ],
   "source": [
    "total_RMLSE_zeros=[]\n",
    "\n",
    "for i,tp in enumerate(testing_pairs):\n",
    "    total_RMLSE_zeros.append(RMLSE((np.array(tp[1].data.view(1,-1)).flatten())[:-2],a[i][:-2]))\n",
    "    print(total_RMLSE_zeros[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33405494964\n",
      "0.623265384787\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_RMLSE))\n",
    "print(np.mean(total_RMLSE_zeros))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM WITH THE DETECTION OF THE ZEROS\n",
    "\n",
    "Necessity to use contextual variables (days of the week, localisation, meteorological data, ...) and longer and deeper training"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
